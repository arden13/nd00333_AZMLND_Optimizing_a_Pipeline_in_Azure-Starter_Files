# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

This is banking data, and we are predicting some y-variable that is binary yes/no but otherwise undefined.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

The best performing model according to Hyperdrive was <ERROR> and I couldn't be bothered to try and figure out which of the delicately-constructed functions caused this problem. In general, Hyperdrive is _supposed_ to perform a search, e.g. grid search or bayesian search, on a distribution of hyperparameters, e.g. normally distributed, uniformly distributed, or lognormally distributed. Grid search is exhaustive but slow while Bayesian is supposed to be smarter in how it searches. The early stopping policy, _should hyperdrive work_ will halt if the search is underperforming. Whopping lot of good it did me here.  It was a pain just to learn AutoML failed at the launch because someone called clean_data() prior to it being defined in train.py.

The best performing model according to AutoML is a LightGBM classifier using maxAbs Scaling.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

We utilized a flat dataset from a web source imported into the TabularDataset azureml class. Then a classifier was constructed and tuned in two different ways.

**What are the benefits of the parameter sampler you chose?**

It predicted the values. 

**What are the benefits of the early stopping policy you chose?**

It prevented spending too much time but for heaven's sake we didn't talk about it all in the class I had to learn about it by searching "BanditPolicy" and digging through Docs. It's incredible ANYONE would pay for this; I only got it through work.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
```python
# Set parameters for AutoMLConfig
# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.
# If you wish to run the experiment longer, you will need to run this notebook in your own
# Azure tenant, which will incur personal costs.
automl_config = AutoMLConfig(
    experiment_timeout_minutes=30,
    task='classification',
    primary_metric='accuracy',
    training_data=ds,
    label_column_name='y',
    n_cross_validations=2)
```
  The config settings limit the timeout to 30 minutes, specify this is a classification task, and tells AutoML to prioritize accuracy over other metrics. The rest of it simply points to the dataset, tells autoML what column to predict, and then defines how many cross validation splits to perform (2).

  
AutoML chose a logistic regression model with C=719.6856730011514. Full pipeline output can be reviewed below:
```
[('datatransformer',
                 DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mnt/batch/tasks/shared/LS_root/mount...
), random_state=0, reg_alpha=0, reg_lambda=1.7708333333333335, subsample=0.9, tree_method='auto'))], verbose=False)), ('12', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('logisticregression', LogisticRegression(C=719.6856730011514, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='multinomial', n_jobs=1, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('13', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('sgdclassifierwrapper', SGDClassifierWrapper(alpha=7.5510448979591835, class_weight='balanced', eta0=0.001, fit_intercept=True, l1_ratio=0.42857142857142855, learning_rate='constant', loss='modified_huber', max_iter=1000, n_jobs=1, penalty='none', power_t=0.7777777777777777, random_state=None, tol=0.0001))], verbose=False))], flatten_transform=None, weights=[0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]))]
```

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

I swear, if you look at the rubric and tell me "Oh hey they didn't say what could be improved" you have no ability to pay attention. Hyperdrive _failed to execute_. I would recommend against using a failed package. There's your improvement. Classic online class of "put all the teaching material in the labs but then never debug them". SKLearn was deprecated by the time this brand new class was launched. Great.
  
In comparison, AutoML computed a result. It didn't error out. To improve it, i'd suggest giving students MORE TIME on the VM so they don't lose progress if they take a piss at the wrong time. If you want more details, give the config longer time and a larger cross validation number. 

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

Presumably throwing more time at the problem would help or a full grid search. I'd also reiterate my suggestion to give students MORE TIME on the VM so they don't lose progress if they take a piss at the wrong time. Also, give the config longer time and a larger cross validation number. 


## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
I did it in code.
